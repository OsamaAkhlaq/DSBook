{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Activity_14_01.ipynb","provenance":[{"file_id":"1yOG_PZqUy9-E885DzHYDwxQxtpTXWBVc","timestamp":1650212333509}],"collapsed_sections":["PqE9wfDvCoqC"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Activity 14.01:**\n","### Fitting a Logistic Regression Model on a HighDimensional Dataset"],"metadata":{"id":"_JY_NwdJSySd"}},{"cell_type":"markdown","source":["### Importing Modules"],"metadata":{"id":"k5wiSFUICXNj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3ZLhsDjB4HU"},"outputs":[],"source":["import pandas as pd\n"]},{"cell_type":"markdown","source":["### Loading  Data"],"metadata":{"id":"PqE9wfDvCoqC"}},{"cell_type":"code","source":["# Defining file name of the git hub repository\n","\n","filename = 'https://raw.githubusercontent.com/fenago/DSBook/main/Chapter%2014/hcvdata.csv'\n"],"metadata":{"id":"HnjcyPM6CPz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the data using pandas\n","\n","adData = pd.read_csv(filename,sep=\",\",header = None,error_bad_lines=False)\n","adData.head()"],"metadata":{"id":"HR08AVBlCRH-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Seperating the dependent and independent variables from the dataset"],"metadata":{"id":"f2sJ3xoXE-RN"}},{"cell_type":"code","source":["# Seperating the dependent and independent variables\n","# Preparing the X variables\n","X = adData.loc[:,0:10]\n","print(X.shape)\n","# Preparing the Y variable\n","Y = adData[11]\n","print(Y.shape)"],"metadata":{"id":"tSbnf3p1Dsot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Replacing special characters with NaN values for first 3 columns"],"metadata":{"id":"Nb6_HuvOFpi3"}},{"cell_type":"code","source":["# Replacing special characters in first 3 columns which are of type object\n","for i in range(0,3):\n","  X[i] = X[i].str.replace(\"?\", 'NaN').values.astype(float)\n","print(X.head(15))"],"metadata":{"id":"hU4RMgRhD7qB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Replacing special characters for Integer values"],"metadata":{"id":"AVL_N5IdF84H"}},{"cell_type":"code","source":["# Replacing special characters in the remaining columns which are of type integer\n","for i in range(3,11):\n","  X[i] = X[i].replace(\"?\", 'NaN').values.astype(float) "],"metadata":{"id":"dBrqtzvDD8Jp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imputing Mean of each column for NaN values using .mean() function"],"metadata":{"id":"h1ADw3WxGX_0"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Imputing the 'NaN'  with mean of the values\n","for i in range(0,10):\n","  X[i] = X[i].fillna(X[i].mean())\n","  \n","print(X.head(15))"],"metadata":{"id":"rAMZZIIPD-sc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Normalizing the dataset using minimaxScaler() function."],"metadata":{"id":"CMrW5QsVGdAr"}},{"cell_type":"code","source":["# Normalising the data sets\n","# Import library function\n","from sklearn import preprocessing\n","# Creating the scaling function\n","minmaxScaler = preprocessing.MinMaxScaler()\n","# Transforming with the scaler function\n","X_tran = pd.DataFrame(minmaxScaler.fit_transform(X))\n","# Printing the output\n","X_tran.head()"],"metadata":{"id":"aLYuvyS8EBVw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating a high dimension dataset"],"metadata":{"id":"rxjyIUubCWun"}},{"cell_type":"code","source":["# Creating a high dimension data set\n","X_hd = pd.DataFrame(pd.np.tile(X_tran, (1, 300)))"],"metadata":{"id":"3V-yhEQdCUrr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Printing the dimension of the data set\n"],"metadata":{"id":"LbjDowJDCaTf"}},{"cell_type":"code","source":["# Printing the dimension of the data set\n","X_hd.shape"],"metadata":{"id":"QuU1uo0iCnlm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Splitting the dataset into train and test sets"],"metadata":{"id":"B2JWYtmwC5Us"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","# Splitting the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_hd, Y, test_size=0.3, random_state=123)"],"metadata":{"id":"niyvvmvHCghf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fitting a logistic regression model on hte new dataset"],"metadata":{"id":"8kUADQ71DDGy"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","import time\n","# Defining the LogisticRegression function\n","benchmarkModel = LogisticRegression()\n","# Starting a timing function\n","t0=time.time()\n","# Fitting the model\n","benchmarkModel.fit(X_train, y_train)\n","# Finding the end time \n","\n","print(\"Total training time:\", round(time.time()-t0, 3), \"s\")"],"metadata":{"id":"7cubD72eCumg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Predicting on the test set"],"metadata":{"id":"HblsrHtwDWj5"}},{"cell_type":"code","source":["# Predicting using the model\n","pred = benchmarkModel.predict(X_test)\n","print('Accuracy of Logistic regression model prediction on test set: {:.2f}'.format(benchmarkModel.score(X_test, y_test)))"],"metadata":{"id":"zP_tdaNTC24E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Printing classification report."],"metadata":{"id":"9U7av_g4De5r"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","# Confusion Matrix for the model\n","print(confusion_matrix(y_test, pred))\n","# Classification report for the model\n","print(classification_report(y_test, pred))"],"metadata":{"id":"ZmxqIwj0CwdL"},"execution_count":null,"outputs":[]}]}