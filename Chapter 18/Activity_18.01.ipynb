{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Activity_18.01.ipynb","provenance":[],"authorship_tag":"ABX9TyMtQ8jwqPoJfVlbMnc9N0k9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Activity 18.01**"],"metadata":{"id":"5urUde3bjDfi"}},{"cell_type":"markdown","metadata":{"id":"1S0KMWrmo75D"},"source":["# Train and Deploy a glass based Model Using Flask"]},{"cell_type":"markdown","source":["### Import the pandas, pickle, joblib, and RandomForestClassifier packages from sklearn.ensemble, as well as train_test_split from sklearn.model_selection:"],"metadata":{"id":"fcTs3YtxIYJD"}},{"cell_type":"code","metadata":{"id":"1pU75pkJo7_j","executionInfo":{"status":"ok","timestamp":1650527745629,"user_tz":-300,"elapsed":407,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["import pandas as pd\n","import joblib\n","import pickle\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zfkjou4Go8EB","executionInfo":{"status":"ok","timestamp":1650527763876,"user_tz":-300,"elapsed":369,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["file_url = 'https://raw.githubusercontent.com/fenago/DSBook/main/Chapter%204/glass.csv'"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNv23FHuo8Gf","executionInfo":{"status":"ok","timestamp":1650527766847,"user_tz":-300,"elapsed":493,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["df = pd.read_csv(file_url)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzGUiiGso8IU","executionInfo":{"status":"ok","timestamp":1650527771423,"user_tz":-300,"elapsed":1096,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["df = pd.read_csv(file_url)"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["###  Extract the 'type' response variable using the .pop() method and save it into a variable called y:"],"metadata":{"id":"Oh70hCwlIcah"}},{"cell_type":"code","metadata":{"id":"Ij49I01To8Oz","executionInfo":{"status":"ok","timestamp":1650527781529,"user_tz":-300,"elapsed":476,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["y = df.pop('Type')"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Create a list called cat_columns containing only the columns of type 'object' using the dtype attribute and print its content"],"metadata":{"id":"qwL9LEH5IgqL"}},{"cell_type":"code","metadata":{"id":"OoLO2WBAo8RB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"43f11422-902c-47b3-ea55-14a34b85bd85","executionInfo":{"status":"ok","timestamp":1650527787382,"user_tz":-300,"elapsed":362,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["cat_columns = [col for col in df.columns if df[col].dtype == 'object']\n","cat_columns"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["### Split the df and y DataFrames into training and test sets using the train_test_split function with the parameters test_size=0.33 and random_state=8:"],"metadata":{"id":"XOysxSNTIlkd"}},{"cell_type":"code","metadata":{"id":"lBPeHGucpL6b","executionInfo":{"status":"ok","timestamp":1650527792774,"user_tz":-300,"elapsed":335,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=8)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"CppSqlVXpL-4","executionInfo":{"status":"ok","timestamp":1650527795278,"user_tz":-300,"elapsed":4,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["column_categories = {}"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["### Iterate through cat_columns and populate the dictionary with the column name and the list of categories using the .astype() method and the .cat.categories attribute:"],"metadata":{"id":"yqYIwM2GIpjk"}},{"cell_type":"code","metadata":{"id":"pMTlUltSpMC3","executionInfo":{"status":"ok","timestamp":1650527797248,"user_tz":-300,"elapsed":5,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["for col in cat_columns:\n","  column_categories[col] = X_train[col].astype('category').cat.categories"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["### Save column_categories and cat_columns into files called categories_data.pkl and categorical_columns.pkl respectively using the pickle.dump() method:"],"metadata":{"id":"8JIossvtItIf"}},{"cell_type":"code","metadata":{"id":"H6iGRvFNpMFy","executionInfo":{"status":"ok","timestamp":1650527800406,"user_tz":-300,"elapsed":3,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["pickle.dump(column_categories, open(\"categories_data.pkl\", \"wb\"))\n","pickle.dump(cat_columns, open(\"categorical_columns.pkl\", \"wb\"))"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["### Create a function called apply_categories that takes a DataFrame and a dictionary as inputs and will import CategoricalDtype from pandas.api.types, iterate through this dictionary,  and convert each column (keys) with the list of categories (values) using the .astype() method and CategoricalDtype:"],"metadata":{"id":"B-m3MXSvIvTA"}},{"cell_type":"code","metadata":{"id":"kiCjE8aYpMBo","executionInfo":{"status":"ok","timestamp":1650527805200,"user_tz":-300,"elapsed":353,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["def apply_categories(input_df, cat_dict):\n","  from pandas.api.types import CategoricalDtype\n","  for col, cat in cat_dict.items():\n","    input_df[col] = input_df[col].astype(CategoricalDtype(categories=cat))\n","  return input_df"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["### Apply this function on X_train and column_categories and save the result in a new DataFrame called X_train_cat. Print the data type of its columns using the .dtypes attribute:"],"metadata":{"id":"qVc5MMv7I1Qo"}},{"cell_type":"code","metadata":{"id":"dVx1meMvo8To","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c0ba35b-ce17-4f3c-bb95-f147fa43e1c0","executionInfo":{"status":"ok","timestamp":1650527807894,"user_tz":-300,"elapsed":9,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["X_train_cat = apply_categories(X_train, column_categories)\n","X_train_cat.dtypes"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RI    float64\n","Na    float64\n","Mg    float64\n","Al    float64\n","Si    float64\n","K     float64\n","Ca    float64\n","Ba    float64\n","Fe    float64\n","dtype: object"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["## Perform one-hot encoding on the categorical columns using the .get_dummies() method and save the result into a new variable called X_train_final:"],"metadata":{"id":"Vyhi_BTwI49P"}},{"cell_type":"code","metadata":{"id":"sm5pLItCqLl5","executionInfo":{"status":"ok","timestamp":1650527811673,"user_tz":-300,"elapsed":400,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["X_train_final = pd.get_dummies(X_train_cat, columns=cat_columns)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["### Instantiate a RandomForestClassifier with random_state=8 and train it with the training sets using the .fit() method. Save the model into a file called model.pkl using the joblib.dump() method:"],"metadata":{"id":"V1GPHgxhI8_d"}},{"cell_type":"code","metadata":{"id":"qqra_2DGqLvC"},"source":["rf_model = RandomForestClassifier(random_state=8)\n","rf_model.fit(X_train_final, y_train)\n","joblib.dump(rf_model, \"model.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Import the socket, threading, requests, json, and numpy packages, the Flask class, and the jsonify and request functions from the flask package:"],"metadata":{"id":"699xrr2PJAWh"}},{"cell_type":"code","metadata":{"id":"cvi0tzPTqLoe","executionInfo":{"status":"ok","timestamp":1650527819495,"user_tz":-300,"elapsed":4,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["import socket\n","import threading\n","import requests\n","import json\n","from flask import Flask, jsonify, request\n","import numpy as np"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["### Create a new Flask app and save it into a variable called app:"],"metadata":{"id":"BJJhwVSeJDJD"}},{"cell_type":"code","metadata":{"id":"9I2GtRq-qfXZ","executionInfo":{"status":"ok","timestamp":1650527822432,"user_tz":-300,"elapsed":739,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["app = Flask(__name__)"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["### Load the pre-trained model from the model.pkl file using joblib.load() and save it into a variable called trained_model. Load the saved dictionary from categories_data.pkl using pickle.load() and save it into a variable called var_means:"],"metadata":{"id":"ziTfYDncJGPY"}},{"cell_type":"code","metadata":{"id":"Sj7IczEtqffI"},"source":["trained_model = joblib.load(\"model.pkl\")\n","var_means = pickle.load(open(\"categories_data.pkl\", \"rb\"))\n","cat_cols = pickle.load(open(\"categorical_columns.pkl\", \"rb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create an API endpoint for the api path that accepts only POST requests and will call a function called predict().This function will read the JSON received using the request.get_json() method, transform it into a DataFrame,  apply the apply_categories() function on it with var_means, perform one-hot encoding with .get_dummies(), predict the outcome with trained_model, convert the prediction from a numpy array to a string with array2string(), and then convert to JSON with jsonify():"],"metadata":{"id":"FLoP3ohBJJo_"}},{"cell_type":"code","metadata":{"id":"kJ1U4oThq3HH","executionInfo":{"status":"ok","timestamp":1650527828795,"user_tz":-300,"elapsed":389,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["@app.route('/api', methods=['POST']) \n","def predict(): \n","  data = request.get_json() \n","  df_test = pd.DataFrame(data, index=[0]) \n","  df_test_clean = apply_categories(df_test, var_means) \n","  df_test_final = pd.get_dummies(df_test_clean, columns=cat_cols) \n","  prediction = trained_model.predict(df_test_final) \n","  str_pred = np.array2string(prediction) \n","  return jsonify(str_pred) "],"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["### Create a new thread for running your Flask app using the threading. Thread method with the following parameters: target=app.run, kwargs={'host':'0.0.0.0','port':80}:"],"metadata":{"id":"rZoYeD6PJNoZ"}},{"cell_type":"code","metadata":{"id":"PUCuG8yBq3VS"},"source":["flask_thread = threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':80})\n","flask_thread.start()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hc4Fxu10rAC2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMpch3-crDLO"},"source":["record = X_test.iloc[0,].to_json()\n","record"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create a dictionary called headers with the following key-value pairs: 'content-type': 'application/json', 'Accept-Charset': 'UTF-8'. Extract into a new variable called ip_address the IP address of the host using the socket.gethostname() and socket.gethostbyname() methods:"],"metadata":{"id":"mxBRG-LbjMrZ"}},{"cell_type":"code","metadata":{"id":"mVhW4VRwrLHZ","executionInfo":{"status":"ok","timestamp":1650527841111,"user_tz":-300,"elapsed":550,"user":{"displayName":"Fatima Zahid","userId":"16414706274409519103"}}},"source":["headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n","ip_address = socket.gethostbyname(socket.gethostname())"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZGhVTCNrNcR"},"source":["r = requests.post(f\"http://{ip_address}/api\", data=record, headers=headers)\n","r.text"],"execution_count":null,"outputs":[]}]}